{"metadata": {"language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.5.4"}, "kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "language": "python", "name": "python3-spark21"}}, "nbformat": 4, "cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "<html>\n<body>\n    <table style=\"border: none\" align=\"center\">\n        <tr style=\"border: none\">\n            <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"45\" width=\"45\"></th>\n            <th style=\"border: none\"><font face=\"verdana\" size=\"6\" color=\"black\"><b>Watson Machine Learning</b></font></th>\n        </tr>\n    </table>\n</body>"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook contains steps and code to train a Scikit-Learn model that uses a custom defined transformer and use it with Watson Machine Learning service. Once the model is trained, this notebook contains steps to persist the model and custom defined transformer to Watson Machine Learning Repository, deploy and score it using Watson Machine Learning python client.\n\nIn this notebook, we use GNFUV dataset that contains mobile sensor readings data about humidity and temperature from Unmanned Surface Vehicles in a test-bed in Athens, to train a Scikit-Learn model for predicting the temperature. \n\nSome familiarity with Python is helpful. This notebook uses Python-3.5, scikit-learn-0.19.1."}, {"metadata": {}, "cell_type": "markdown", "source": "## Learning goals\n\nThe learning goals of this notebook are:\n\n- Train a model with custom defined transformer\n- Persist the custom defined transformer and the model in Watson Machine Learning repository.\n- Deploy the model using Watson Machine Learning Service\n- Perform predictions using the deployed model\n\n## Contents\n1.\t[Set up the environment](#setup)\n2.\t[Install python library containing custom transformer implementation](#install_lib)\n3.  [Prepare training data](#load)\n3.\t[Train the scikit-learn model](#train)\n4.\t[Save the model and library to WML Repository](#persistence)\n5.\t[Deploy and score data in the IBM Cloud](#deploy)\n6.\t[Summary and next steps](#summary)\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a [Watson Machine Learning (WML) Service](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/) instance (a free plan is offered and information about how to create the instance is [here](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html))\n\n- Configure your local python environment:\n  + python 3.5\n  + scikit-learn 0.19.1\n  + watson-machine-learning-client, version: 1.0.293 or above"}, {"metadata": {}, "cell_type": "markdown", "source": "**Tip**: Run the cell below to install libraries from <a href=\"https://pypi.python.org/pypi\" target=\"_blank\" rel=\"noopener no referrer\">PyPI</a>."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!rm -rf $PIP_BUILD/watson-machine-learning-client"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!pip install watson-machine-learning-client --upgrade"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"install_lib\"></a>\n\n## 2. Install the library containing custom transformer"}, {"metadata": {}, "cell_type": "markdown", "source": "The library - `linalgnorm-0.1.zip` is a python distributable package that contains the implementation of a user defined Scikit-Learn transformer - `LNormalizer` . <br>\nAny 3rd party libraries that are required for the custom transformer must be defined as the dependency for the corresponding library that contains implementation of the transformer. \n\n\nIn this section, we download the library and install it in the current notebook environment. "}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "cd ~/data/libs"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!wget https://github.com/pmservice/wml-sample-models/raw/master/scikit-learn/custom-transformer-temperature-prediction/libraries/linalgnorm-0.1.zip --output-document=linalgnorm-0.1.zip"}, {"metadata": {}, "cell_type": "markdown", "source": "Install the downloaded library using `pip` command"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "ls -ltr"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!pip install linalgnorm-0.1.zip"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"load\"></a>\n\n## 3. Download training dataset and prepare training data"}, {"metadata": {}, "cell_type": "markdown", "source": "Download the data from UCI repository - https://archive.ics.uci.edu/ml/machine-learning-databases/00452/GNFUV%20USV%20Dataset.zip"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!rm -rf dataset\n!mkdir dataset"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00452/GNFUV%20USV%20Dataset.zip --output-document=dataset/gnfuv_dataset.zip"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "cd dataset"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "!unzip gnfuv_dataset.zip"}, {"metadata": {}, "cell_type": "markdown", "source": "Create pandas datafame based on the downloaded dataset"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "import json\nimport pandas as pd\nimport numpy as np\nimport os\nfrom datetime import datetime\nfrom json import JSONDecodeError"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "## Get all the entries\nhome_dir = '.'\npi_dirs = os.listdir(home_dir)\n\ndata_list = []\nbase_time = None\ncolumns = None\n\nfor pi_dir in pi_dirs:\n    if 'pi' not in pi_dir:\n        continue\n    curr_dir = os.path.join(home_dir, pi_dir)\n    data_file = os.path.join(curr_dir, os.listdir(curr_dir)[0])\n    with open(data_file, 'r') as f:\n        line = f.readline().strip().replace(\"'\", '\"')\n        while line != '':\n            try:\n                input_json = json.loads(line)\n                sensor_datetime = datetime.fromtimestamp(input_json['time'])\n                if base_time is None:\n                    base_time = datetime(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day, 0, 0, 0, 0)\n                input_json['time'] = (sensor_datetime - base_time).seconds\n                data_list.append(list(input_json.values()))\n                if columns is None:\n                    columns = list(input_json.keys())\n            except JSONDecodeError as je:\n                pass\n            line = f.readline().strip().replace(\"'\", '\"')\n\ndata_df = pd.DataFrame(data_list, columns=columns)"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "data_df.head()"}, {"metadata": {}, "cell_type": "markdown", "source": "Create training and test datasets from the downloaded GNFUV-USV dataset."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cross_validation import train_test_split\n\nY = data_df['temperature']\nX = data_df.drop('temperature', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=143)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"train\"></a>\n\n## 4. Train a model\n\nIn this section, you will use the custom transformer as a stage in the Scikit-Learn `Pipeline` and train a model."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Import the custom transformer \nHere, import the custom transformer that has been defined in `linalgnorm-0.2.zip` and create an instance of it that will inturn be used as stage in `sklearn.Pipeline`"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "from linalg_norm.sklearn_transformers import LNormalizer"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "lnorm_transf = LNormalizer()"}, {"metadata": {}, "cell_type": "markdown", "source": "Import other objects required to train a model"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression"}, {"metadata": {}, "cell_type": "markdown", "source": "Now, you can create a `Pipeline` with user defined transformer as one of the stages and train the model"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "\nskl_pipeline = Pipeline(steps=[('normalizer', lnorm_transf), ('regression_estimator', LinearRegression())])\nskl_pipeline.fit(X_train.loc[:, ['time', 'humidity']].values, y_train)\n"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "y_pred = skl_pipeline.predict(X_test.loc[:, ['time', 'humidity']].values)\nrmse = np.mean((np.round(y_pred) - y_test.values)**2)**0.5\nprint('RMSE: {}'.format(rmse))"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"persistence\"></a>\n\n## 5. Persist the model and custom library to WML Repository\n\nIn this section, using `watson_machine_learning_client`, you will ...\n- save the library `linalgnorm-0.1.zip` in WML Repository by creating a Library resource\n- create a Runtime resource and bind the Library resource to it. This Runtime resource will be used to configure the online deployment runtime environment for a model \n- bind Runtime resource to the model and save the model to WML Repository"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient"}, {"metadata": {}, "cell_type": "markdown", "source": "Authenticate to the Watson Machine Learning service on IBM Cloud.\n\n**Tip**: Authentication information (your credentials) can be found in the [Service Credentials](https://console.bluemix.net/docs/services/service_credentials.html#service_credentials) tab of the service instance that you created on IBM Cloud. <BR>If you cannot see the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n\n**Action**: Enter your Watson Machine Learning service instance credentials here.\n"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "\nwml_credentials={\n  \"url\": \"https://wml.test.cloud.ibm.com\",\n  \"access_key\": \"****\",\n  \"username\": \"xxxxxxxxxxxxxxxxx\",\n  \"password\": \"xxxxxxxxxxxxxxxxx\",\n  \"instance_id\": \"xxxxxxxxxxxxxxxxx\"\n}\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "**Create WML API client**"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "client = WatsonMachineLearningAPIClient(wml_credentials)"}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.1 Save Library in WML Repository"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "cd ~/data/libs"}, {"metadata": {}, "cell_type": "markdown", "source": "Define the meta data required to create Library resource and save the library. <br>\n\nThe value for `client.runtimes.LibraryMetaNames.FILEPATH` metadata contains the library file name that must be saved to WML Repository"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "lib_meta = {\n        client.runtimes.LibraryMetaNames.NAME: \"K_Linag_norm_skl\",\n        client.runtimes.LibraryMetaNames.DESCRIPTION: \"K_Linag_norm_skl\",\n        client.runtimes.LibraryMetaNames.FILEPATH: \"linalgnorm-0.1.zip\",\n        client.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n        client.runtimes.LibraryMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.5\"]}\n    }\ncustom_library_details = client.runtimes.store_library(lib_meta)\ncustom_library_uid = client.runtimes.get_library_uid(custom_library_details)\nprint(\"Custom Library UID: \" + custom_library_uid)"}, {"metadata": {}, "cell_type": "markdown", "source": "Display the details of the Library resource that was created in the above cell"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "custom_library_details"}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.2 Create Runtime and bind library to runtime"}, {"metadata": {}, "cell_type": "markdown", "source": "Define the meta data required to create Runtimes resource and bind the library. This Runtime resource will be used to configure the online deployment runtime environment for a model.\n\nThe `client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS` metadata property is used to specify the list of Library resource GUIDs that needs to be part of the runtime."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "runtimes_meta = {\n    client.runtimes.ConfigurationMetaNames.NAME: \"K_linalg_gnfuv1\", \n    client.runtimes.ConfigurationMetaNames.DESCRIPTION: \"skl linalg gnfuv model\", \n    client.runtimes.ConfigurationMetaNames.PLATFORM: { \"name\": \"python\", \"version\": \"3.5\" }, \n    client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [custom_library_uid]\n}"}, {"metadata": {}, "cell_type": "markdown", "source": "**Alternate method:** Create library and runtime together by specifying the metadata property below\n\n`client.runtimes.ConfigurationMetaNames.LIBRARIES_DEFINITIONS: [\n    LibraryDefinition(\"my_lib_1\", \"1.0\", \"/home/user/my_lib_1.zip\", description=\"t\", platform={\"name\": \"python\", \"versions\": [\"3.5\"]}), \n    LibraryDefinition(\"my_lib_2\", \"1.1\", \"/home/user/my_lib_2.zip\") ]`"}, {"metadata": {}, "cell_type": "markdown", "source": "Create a Runtime resource based on the metadata specified above and display the details"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "runtime_details = client.runtimes.store(runtimes_meta)\nruntime_details"}, {"metadata": {}, "cell_type": "markdown", "source": "APIs to retrieve URL and GUID information about a spepcific Runtime"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "runtime_url = client.runtimes.get_url(runtime_details)\nruntime_uid = client.runtimes.get_uid(runtime_details)\nprint(\"Runtimes URL: \" + runtime_url)\nprint(\"Runtimes UID: \" + runtime_uid)"}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.3 Save the model"}, {"metadata": {}, "cell_type": "markdown", "source": "Define the metadata to save the trained model to WML Repository along with the information about the Runtime resource required for the model. \n\nThe `client.repository.ModelMetaNames.RUNTIME_UID` metadata property is used to specify the GUID of the Runtime resource that needs to be associated with the model "}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "model_props = {client.repository.ModelMetaNames.NAME: \"cust norm linalg_norm gnfuv1\",\n               client.repository.ModelMetaNames.RUNTIME_UID: runtime_uid\n              }"}, {"metadata": {}, "cell_type": "markdown", "source": "Save the model to the WML Repository and display its saved metadata. "}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "published_model = client.repository.store_model(model=skl_pipeline, meta_props=model_props)"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "published_model_uid = client.repository.get_model_uid(published_model)\nmodel_details = client.repository.get_details(published_model_uid)\nprint(json.dumps(model_details, indent=2))"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deploy\"></a>\n\n## 6 Deploy and Score\n\nIn this section, you will deploy the saved model that uses the custom transformer and perform predictions. You will use WML client to perform these tasks."}, {"metadata": {}, "cell_type": "markdown", "source": "### 6.1 Deploy the model"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "created_deployment = client.deployments.create(published_model_uid, name=\"k_linalg_gnfuv1_skl\")\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### 6.2 Predict using the deployed model"}, {"metadata": {}, "cell_type": "markdown", "source": "Get the URL to use for prediction. The prediction URL is obtained from the deployment details of the deployment created above."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\nprint(scoring_endpoint)"}, {"metadata": {}, "cell_type": "markdown", "source": "Prepare the payload for prediction. The payload contains the input records for which predictions has to be performed."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "scoring_payload = {'fields': [\"time\", \"humidity\"], \n                   'values': [[79863, 47]]}"}, {"metadata": {}, "cell_type": "markdown", "source": "Execute the method to perform online predictions and display the prediction results"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "predictions = client.deployments.score(scoring_endpoint, scoring_payload)"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "print(json.dumps(predictions, indent=2))\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### 6.3 Delete the deployments"}, {"metadata": {}, "cell_type": "markdown", "source": "Use the following method to delete the deployment "}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": "client.deployments.delete(client.deployments.get_uid(created_deployment))"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"summary\"></a>\n\n### 7. Summary\n\nYou successfully completed this notebook! \n \nYou learned how to use a scikit-learn model with custom transformer in Watson Machine Learning service to deploy and score.\n\nCheck out our [Online Documentation](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html) for more samples, tutorials, documentation, how-tos, and blog posts. "}, {"metadata": {}, "cell_type": "markdown", "source": "## Author\n\n**Krishnamurthy Arthanarisamy**, is a senior technical lead in IBM Watson Machine Learning team. Krishna works on developing cloud services that caters to different stages of machine learning and deep learning modeling life cycle."}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": null, "source": ""}], "nbformat_minor": 1}