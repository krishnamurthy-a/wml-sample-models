{"nbformat_minor": 1, "metadata": {"language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}}, "kernelspec": {"name": "python3-spark21", "language": "python", "display_name": "Python 3.5 with Spark 2.1"}}, "cells": [{"source": "<html>\n<body>\n    <table style=\"border: none\" align=\"center\">\n        <tr style=\"border: none\">\n            <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"45\" width=\"45\"></th>\n            <th style=\"border: none\"><font face=\"verdana\" size=\"6\" color=\"black\"><b>Watson Machine Learning</b></font></th>\n        </tr>\n    </table>\n</body>", "metadata": {}, "cell_type": "markdown"}, {"source": "This notebook contains steps and code to define a custom operation using tf.py_func operation in tensorflow. The custom operation is then used in a LeNet network for handwritten character recognition which is trained on the MNIST dataset. The trained model is persisted, deployed and scored using the Watson Machine Learning Service and the Watson Machine Learning Client.\n\nSome familiarity with Python is helpful. This notebook uses Python-3.5, numpy-1.14 and tensorflow-1.5.\n\n## Learning goals\n\nThe learning goals of this notebook are:\n\n-  Define a custom operation and corresponding gradient using `tf.py_func`\n-  Create a LeNet model using the defined custom operation\n-  Train the model on the MNIST dataset\n-  Create a library containing the custom tensor operation\n-  Persist the library and the model in Watson Machine Learning repository.\n-  Deploy the model using Watson Machine Learning Service\n-  Perform some classifications using the deployed model\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.  [Setup the environment](#setup)\n1.  [Create operation for tf.py_func and download library](#func)\n2.\t[Load data and initialize parameters](#load)\n3.\t[Create and train Lenet model](#model)\n4.  [Save model locally](#save)\n5.  [Persist library and runtime resource](#lib_persistence)\n6.\t[Persist Lenet model in Cloud](#persistence)\n7.  [Deploy and perform prediction on the Lenet model](#Scoring)\n8.  [Summary](#summary)\n", "metadata": {}, "cell_type": "markdown"}, {"source": "<a id=\"setup\"></a>\n## 1. Set up the environment\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n\n-  Create a [Watson Machine Learning (WML) Service](https://console.bluemix.net/catalog/services/machine-learning) instance (a lite  plan is offered and information about how to create the instance is [here](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html))\n- Configure your local python environment:\n  + python 3.5\n  + tensorflow 1.5\n  + watson-machine-learning-client, version: 1.0.293 or above\n", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "!rm -rf $PIP_BUILD/watson-machine-learning-client", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"scrolled": false}, "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"func\"></a>\n## 2. Create operation for tf.py_func and download library\n", "metadata": {}, "cell_type": "markdown"}, {"source": "### 2.1 Create custom operation for tf.py_func", "metadata": {}, "cell_type": "markdown"}, {"source": "While creating a custom operation for tf.py_func, it is also necessary to create the corresponding gradient function. Tensorflow maps any function passed to tf.py_func under the `PyFunc` operation type. Tensorflow models perform gradient calculation during training. Hence, a user defined `tf.py_func` operation requires a corresponding gradient function defined and mapped to the `PyFunc` operation type. In this example, `reshape_grad` is the gradient function for the `tf.py_func` operation.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.framework import ops \n\ndef reshape_func(x):\n    return x.reshape((-1, 28, 28, 1)) \n\ndef reshape_grad(op, grad):\n    x = op.inputs[0]\n\n    return grad\n\ndef create_py_func_with_grads(op, inp, tout, stateful=True, name=None, grad=None):\n    grad_name = 'PyFuncGrad' + str(np.random.randint(0, 1e+8))\n\n    tf.RegisterGradient(grad_name)(grad)\n    g = tf.get_default_graph()\n\n    with g.gradient_override_map({\"PyFunc\": grad_name}):\n        return tf.py_func(op, inp, tout, stateful=stateful, name=name)\n", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### 2.2 Downloading library", "metadata": {}, "cell_type": "markdown"}, {"source": "In order to store and deploy models that use operations defined through `tf.py_func`, a python distributable library needs to be created. The library should contain an `initialize_py_func()` function which defines the `tf.py_func` operation. The operation defined within this function should have the same name as the operation created during model definition and training. Also, `initialize_py_func()` function must be referenceable using the top-level module name. For example, if top-level \nmodule in the python distribution package is `my_top_module`, then `initialize_py_func()` must be referenceable as \n`my_top_module.initialize_py_func()`.\n\nCurrently, only source distributed libraries archived in `.zip` format are supported. Libraries distributions of type `wheels` and `eggs` are not supported\n\nAny 3rd party libraries that are required for the custom transformer must be defined as the dependency for the corresponding library that contains implementation of the transformer. ", "metadata": {}, "cell_type": "markdown"}, {"source": "Here, we download the library `custom_reshape_pyfunc.zip` which defines the reshape operation", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "!wget https://github.com/pmservice/wml-sample-models/raw/master/tensorflow/custom-op-hand-written-digit-recognition/libraries/custom_reshape_pyfunc-0.1.zip --output-document=custom_reshape_pyfunc.zip", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"load\"></a>\n## 3. Load data and initialize parameters", "metadata": {}, "cell_type": "markdown"}, {"source": "Downloading the MNIST dataset from Yann LeCunn's homepage using the built-in tensorflow library", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "from tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "Setting Training and network parameters", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "# Training Parameters\nlearning_rate = 0.001\ntraining_iters = 10000\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nn_input = 784 \nn_classes = 10 ", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"model\"></a>\n## 4. Create and train Lenet model", "metadata": {}, "cell_type": "markdown"}, {"source": "### 4.1 Model creation", "metadata": {}, "cell_type": "markdown"}, {"source": "Defining placeholders and the default layer configurations for the network", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "# tf Graph input\nx = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\ny = tf.placeholder(tf.float32, [None, n_classes])\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "The `create_py_func_with_grads` function defines a `tf.py_func` operation along with the corresponding gradient and returns the resulting tensor.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "x_trans1 = create_py_func_with_grads(reshape_func, [x], tf.float32, False, name='ReshapeFunc', grad=reshape_grad)\n\n# Convolution Layer -1\nx_conv2d_l1 = tf.nn.conv2d(x_trans1, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\nx_w_bias_l1 = tf.nn.bias_add(x_conv2d_l1, biases['bc1'])\nx_relu_l1 = tf.nn.relu(x_w_bias_l1)\nconv1_out = tf.nn.max_pool(x_relu_l1,\n                           ksize=[1, 2, 2, 1],\n                           strides=[1, 2, 2, 1],\n                           padding='SAME')\n\n\n# Convolution Layer -2\nx_conv2d_l2 = tf.nn.conv2d(conv1_out, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\nx_w_bias_l2 = tf.nn.bias_add(x_conv2d_l2, biases['bc2'])\nx_relu_l2 = tf.nn.relu(x_w_bias_l2)\nconv2_out = tf.nn.max_pool(x_relu_l2,\n                           ksize=[1, 2, 2, 1],\n                           strides=[1, 2, 2, 1],\n                           padding='SAME')\n\n# Fully connected layer\n# Reshape conv2 output to fit fully connected layer input\nfc1 = tf.reshape(conv2_out, [-1, weights['wd1'].get_shape().as_list()[0]])\nfc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\nfc1 = tf.nn.relu(fc1)\n\n# Output, class prediction\nconv_out = tf.add(tf.matmul(fc1, weights['out']), biases['out'], name=\"output_tensor\")\n\npredictor = tf.argmax(conv_out, 1, name=\"predictor\")\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_out, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# To Evaluate model\ncorrect_pred = tf.equal(tf.argmax(conv_out, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "Training the model", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "# Initializing the variables\ninit = tf.global_variables_initializer()\n# Launch the graph\nsess = tf.Session()\nsess.run(init)\nstep = 1\n# Keep training until reach max iterations\nwhile step * batch_size < training_iters:\n    batch_x, batch_y = mnist.train.next_batch(batch_size)\n    # Run optimization op (backprop)\n    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n    print(\"Completed batch iteration: \" + str(step*batch_size) )\n    if step % display_step == 0:\n        # Calculate batch loss and accuracy\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                          y: batch_y})\n    \n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n              \"{:.5f}\".format(acc))\n    step += 1\nprint(\"Model training finished!\")", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"save\"></a>\n\n## 5. Save model locally", "metadata": {}, "cell_type": "markdown"}, {"source": "### 5.1 Save model locally using SavedModelBuilder", "metadata": {}, "cell_type": "markdown"}, {"source": "Remove previously created directory", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "import os, shutil\nsave_path = './tf_model_mnist_test'\n# delete dir if directory exists\nif os.path.exists(save_path):\n    shutil.rmtree(save_path)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "Create SignatureDef metadata for the model", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "classification_inputs = tf.saved_model.utils.build_tensor_info(x)\nclassification_outputs_classes = tf.saved_model.utils.build_tensor_info(predictor)\n\nclassification_signature = (\n      tf.saved_model.signature_def_utils.build_signature_def(\n          inputs={\n              tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n                  classification_inputs\n          },\n          outputs={\n              tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n                  classification_outputs_classes\n          },\n          method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n\nprint(\"classification_signature content:\")\nprint(classification_signature)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "Save the LeNet model locally using Tensorflow's SavedModelBuilder API", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "# Build the signature_def_map.\n\nbuilder = tf.saved_model.builder.SavedModelBuilder(save_path)\nlegacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\nbuilder.add_meta_graph_and_variables(\n      sess, [tf.saved_model.tag_constants.SERVING],\n      signature_def_map={\n          'predict_images': classification_signature,\n      },\n      legacy_init_op=legacy_init_op)\n\nbuilder.save()", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"lib_persistence\"></a>\n## 6. Persist library and model in WML Repository\n\n\nIn this section, using `watson_machine_learning_client`, you will ...\n- save the library `custom_reshape_pyfunc.zip` in WML Repository by creating a Library resource\n- create a Runtime resource and bind the Library resource to it. This Runtime resource will be used to configure the online deployment runtime environment for a model \n", "metadata": {}, "cell_type": "markdown"}, {"source": "#### Saving the library as a library artifact in the WML repository", "metadata": {}, "cell_type": "markdown"}, {"source": "Authenticate to the Watson Machine Learning (WML) service on IBM Cloud.\n\n**Tip**: Authentication information (your credentials) can be found in the [Service credentials](https://console.bluemix.net/docs/services/service_credentials.html#service_credentials) tab of the service instance that you created on IBM Cloud. \nIf there are no credentials listed for your instance in **Service credentials**, click **New credential (+)** and enter the information required to generate new authentication information. \n\n**Action**: Enter your WML service instance credentials here.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "wml_credentials={\n  \"url\": \"https://wml.test.cloud.ibm.com\",\n  \"access_key\": \"****\",\n  \"username\": \"xxxxxxxxxxxxxxxxx\",\n  \"password\": \"xxxxxxxxxxxxxxxxx\",\n  \"instance_id\": \"xxxxxxxxxxxxxxxxx\"\n}\n\n", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "client = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "While creating the library metadata for storing the library in WML Repository, one must make sure that the value passed to `client.runtimes.LibraryMetaNames.NAME` key is the same as the value passed to the `name` parameter of `setup()` function in `setup.py` file which is used to build the library.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "cust_lib_zip_path = \"custom_reshape_pyfunc.zip\"", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "lib_meta = {\n    client.runtimes.LibraryMetaNames.NAME: \"custom_reshape_pyfunc\",\n    client.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom pyfunc lib which reshapes input\",\n    client.runtimes.LibraryMetaNames.FILEPATH: cust_lib_zip_path,\n    client.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n    client.runtimes.LibraryMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.5\"]}\n}", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "custom_library_details = client.runtimes.store_library(lib_meta)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "custom_library_uid = client.runtimes.get_library_uid(custom_library_details)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "custom_library_uid", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "#### Saving a Runtime Resource artifact in WML Repository\nThe Runtime Resource Artifact contains references to a collection of all the custom libraries that need to be used together to deploy the concerned model.\nWhile creating the metadata to store the runtime artifact, pass a list of library uids that need to be used to the `client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS` key.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "runtime_meta = {\n    client.runtimes.ConfigurationMetaNames.NAME: 'runtime_mnist',\n    client.runtimes.ConfigurationMetaNames.DESCRIPTION: 'runtime spec - mnist',\n    client.runtimes.ConfigurationMetaNames.PLATFORM: {\n        \"name\": \"python\",\n        \"version\": \"3.5\"\n    },\n    client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [custom_library_uid]\n}\nruntime_details = client.runtimes.store(runtime_meta)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "runtime_details", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "custom_runtime_uid = client.runtimes.get_uid(runtime_details)\nprint(custom_runtime_uid)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"persistence\"></a>\n## 7. Persist Lenet model in Cloud", "metadata": {}, "cell_type": "markdown"}, {"source": "The model that needs to be saved in the repo needs to be of tar.gz format.", "metadata": {}, "cell_type": "markdown"}, {"source": "First, we remove any existing model archive with the same name and then create a new one", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "if os.path.exists('tf_mnist_pyfunc.tar.gz'):\n    os.remove('tf_mnist_pyfunc.tar.gz')", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "cd tf_model_mnist_test", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "ls", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "!tar -cvf ../tf_mnist_pyfunc.tar *", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "cd ../", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "!gzip tf_mnist_pyfunc.tar", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "model_path = 'tf_mnist_pyfunc.tar.gz'", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "#### Saving the model to WML Repository\nBind Runtime resource to the model and save the model to WML Repository. <br>\n`client.repository.ModelMetaNames.RUNTIME_UID` key value pair is added to the model metadata as a reference to the runtime artifact which stores the list of library artifact urls.", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "model_meta = {\n    client.repository.ModelMetaNames.AUTHOR_NAME: \"IBM\",\n    client.repository.ModelMetaNames.AUTHOR_EMAIL: \"ibm@ibm.com\",\n    client.repository.ModelMetaNames.NAME: \"cust_pyfunc_mnist\",\n    client.repository.ModelMetaNames.DESCRIPTION: \"cust MNIST with pyfunc\",\n    client.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid,\n    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\",\n    client.repository.ModelMetaNames.RUNTIME_NAME: \"python\",\n    client.repository.ModelMetaNames.RUNTIME_VERSION: \"3.5\"\n}\nmodel_details = client.repository.store_model(model=model_path, meta_props=model_meta)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "model_uid = client.repository.get_model_uid(model_details)\nprint(model_uid)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "model_details", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id='Scoring'></a>\n## 8. Deploy and perform prediction on the Lenet model", "metadata": {}, "cell_type": "markdown"}, {"source": "In this section, you will deploy the saved model that uses the custom transformer and perform predictions. You will use WML client to perform these tasks.", "metadata": {}, "cell_type": "markdown"}, {"source": "### 8.1 Model Deployment", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "deployment_details = client.deployments.create(model_uid, \"Mnist model deployment\")", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### 8.2 Score the deployed model", "metadata": {}, "cell_type": "markdown"}, {"source": "Get the scoring url for the model", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "scoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "Prepare sample scoring data", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "import matplotlib.pyplot as plt\nimport numpy as np", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "image = mnist.test.next_batch(1)[0].tolist()\npayload = {'values': image}", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "plt.subplot(1, 1, 1)\nplt.axis('off')\nplt.imshow((np.reshape(np.array(image), (28, 28)) * 255).astype(np.uint8), cmap=plt.cm.gray_r, interpolation='nearest')", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "predictions = client.deployments.score(scoring_url, payload)\nprint('Scoring result: ' + str(predictions['values']))", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### 8.3 Delete the deployed model", "metadata": {}, "cell_type": "markdown"}, {"source": "Use the following method to delete the deployment when it is not needed", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "deployment_id = client.deployments.get_uid(deployment_details)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {}, "source": "client.deployments.delete(deployment_id)", "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "<a id=\"summary\"></a>\n## 9. Summary", "metadata": {}, "cell_type": "markdown"}, {"source": "In this notebook we learnt how to create a custom python operation using Tensorflow's `tf.py_func` and used it on the LeNet model for MNIST.", "metadata": {}, "cell_type": "markdown"}, {"source": "We also learnt how to use `watson-machine-learning-client` to store a library created for using the same operation into WML Repository.", "metadata": {}, "cell_type": "markdown"}, {"source": "Finally, we stored our custom LeNet model with references to the created library into WML Repository which could be deployed and scored later using WML Service.", "metadata": {}, "cell_type": "markdown"}, {"source": "To explore the functionalities of Watson Studio further, check out our [Online Documentation](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html) for more samples, tutorials, documentation, how-tos, and blog posts.", "metadata": {}, "cell_type": "markdown"}, {"source": "### Citations", "metadata": {}, "cell_type": "markdown"}, {"source": "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.", "metadata": {}, "cell_type": "markdown"}, {"source": "### Authors\n\n**Srikrishna S Bhat**, M. Tech, is a Software Engineer at IBM Watson Machine Learning Team", "metadata": {}, "cell_type": "markdown"}, {"metadata": {}, "source": "", "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4}